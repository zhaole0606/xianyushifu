## 地址空间
早期操作系统程序都很简，也没有多线程的概念，在程序运行时直接加载到真实物理内存中。慢慢的对系统和程序的要求越来越高，又出现了时分系统，交互性也逐渐占据用户主导，大家都希望自己的操作在计算机上得到很快的响应。
早期为了实现时分方法是让一个进程单独占用全部内存一段时间，然后停止它，保存它所有的状态信息到磁盘，再加载其他进程。这种方法实在太慢，一是因为磁盘访问太慢，二是保存的数据量实在太大。后来优化为切换进程仍然将进程信息保存在内存中。
随着时分系统更加流行，多进程下保护变得更加重要，进程之间的内存应该相互独立，不能互相干扰。
操作系统提供了一个物理内存的抽象，叫**地址空间**。这个空间是运行中程序能看到的系统内存。
一个进程的地址空间**包含运行程序的所有内存状态**，包括但不限于代码，堆，栈等等。操作系统通过虚拟化物理内存为多个运行的进程构建一个私有的地址空间抽象。所以这个空间就是**虚拟内存**，而程序加载在上面的地址就是**虚拟内存地址**。
下面说下虚拟化应该达到的三个目标
**透明性**：系统进行虚拟化内存要保证对运行的程序黑盒，程序不应该知道内存被虚拟化了。程序在虚拟内存中运行应跟在物理内存中运行一样。至于虚拟内存地址到物理地址怎么转换是交给操作系统完成。
**效率**，操作系统虚拟化的过程如何保持高效，在虚拟内存中运行程序不应该变慢，并且不需要额外的内存支持虚拟化。
**保护**：操作系统应该确保进程受到保护，不受其他进程影响，其中也包括操作系统自身。进程之间应该有隔离的特性，都在自己独立的环境中运行。
## 地址转换
基于硬件的地址转换来将虚拟地址转换为物理地址。每次指令获取，数据读取/写入硬件都将指令中的虚拟地址转换为数据实际存储的物理地址。设置好硬件，操作系统还需要管理内存，记录被占用和空闲的内存位置，保持对内存的使用控制。
### 基址加界限(动态重定位)
 早些时候使用**基址加界限(动态重定位)** 的方式实现虚拟内存到物理内存的映射，**基址寄存器**存储了一个进程的虚拟内存空间在物理内存中的开始位置。**界限寄存器**存储了一个进程的虚拟内存空间的大小或边界，它表示了虚拟地址空间的结束位置相对于基址寄存器所指示的起始位置的偏移量。
 >[!warning]
 >基址加界限（Base and Bounds）机制主要用来**限制进程对虚拟地址的访问范围**，而不是对整个进程的虚拟地址空间大小进行限制。具体来说，基址加界限机制通过基址寄存器和界限寄存器来管理和控制进程的虚拟地址空间内的访问范围。并且**进程运行期间范围保持不变**。
 
进程只能访问在这个范围内的虚拟地址，而对于超出这个范围的虚拟地址的访问将会触发异常。这种机制提供了一种简单而有效的内存访问控制方法，可以防止程序越界访问内存，提高系统的安全性和稳定性。
内存管理单元MMU是计算机系统中负责管理虚拟地址到物理地址映射的硬件组件。基址加界限通常是在MMU中实现的一种机制。
### 基址加界限的不足
1. 内部碎片化
 基址加界限为每个程序划分了虚拟内存的范围，但是每个程序不一定能完全使用，这就会造成浪费产生了内部碎片。
2. 外部碎片化
内存中有多个程序在运行，他们各自的内存空间相邻位置会留下间隙，这些间隙太小没法容纳新的程序，从而导致外部碎片化。
3. 不灵活
 每个程序的虚拟内存空间都是静态定义的，没法动态调整。如果程序需要更多内存的时候系统就要重新分配。就会导致性能下降和额外的系统开销。
4. 安全性限制
由于每个程序都有固定内存范围，攻击者可以进行越界房屋内或者攻击其他程序内存空间。
### 基址加界限总结
综上所述，基址加界限机制虽然是一种简单的内存管理方法，但它存在一些劣势，包括内部碎片化、外部碎片化、缺乏灵活性和较低的安全性。随着计算机系统的发展，更先进的内存管理技术已经取代了基址加界限机制。
## 段
段是一种内存管理技术，将内存分割成若干段来组织管理程序的空间。将代码，数据和堆栈分开管理。每个段拥有自己的一对基址和界限寄存器来记录各自段的大小。**每个段在物理内存中需要一块连续的空间存储。而程序则不需要，程序只要保证在虚拟内存中是一块连续的空间就可以了**。程序在虚拟地址空间中的每个段都需要在物理内存中分配一块相应大小的连续空间来存储。
### 段的特点
1. 逻辑结构化
分段使程序的逻辑结构更清晰，可以将代码、数据和堆栈等不同类型的信息分开管理。这样可以提高程序的可读性和可维护性。
2. 内存保护
通过分段，可以为不同类型的数据和代码设置不同的访问权限，从而实现内存保护。例如，可以将代码段设置为只读，防止程序意外修改代码；数据段可以设置为可读写，但不可执行，以防止数据被误认为代码执行。
3. 动态增长
分段允许每个段的大小动态增长，这意味着程序可以根据需要动态地分配内存空间。这种灵活性对于某些类型的应用程序（如动态内存分配的程序）非常重要。
4. 共享与保护
分段允许不同的程序段共享相同的内存段，从而节省内存空间。同时，也可以保护不同的程序段，使它们不会相互干扰或意外修改彼此的数据。
5. 虚拟内存管理
分段是实现虚拟内存管理的基础之一。通过将物理内存映射到不同的逻辑段，可以实现虚拟内存的抽象，从而使每个进程都认为自己拥有连续的内存空间，而不受物理内存大小的限制。
### 段的不足
1. 碎片化问题
虽然比上面说的动态重定位方式好。但段的存在依旧有内部和外部碎片化问题。由于，所以能一定程度上充分利用内存空间，但是可能受**分配单位限制**，比如操作系统规定分配的内存空间必须以某个固定大小为单位，那么即使段大小可以动态调整，但依旧会导致一些小的空闲无法被利用。可能受**分配策略**影响，各种分配策略算法带来的影响也会导致可能留下一些较小的空间。最后是**内存释放不连续**导致的，程序释放一部分内存空间时，被释放的空间不是连续的（释放物理内存不是连续），就会导致即便剩下空间无法填充其他段。即便填充的是同段的数据，如果释放的内存碎片没有向应大小的连续空间也是无法填充的。
2. 动态内存分配问题
段式内存管理不适合频繁进行动态内存分配和释放。因为会增加空间不连续性。
3. 地址空间保护难度
每个段的大小和权限都是固定的，对于一些需要动态变化权限的场景，管理起来不灵活。
4. 地址转换复杂性
由于段式内存管理需要对每个段进行单独的地址转换，因此可能会增加地址转换的复杂性和开销。特别是当程序拥有大量的段时，段表的维护和管理可能会变得复杂。
## 分页
针对于段的内存管理出现的碎片化问题，管理颗粒度不够细致等一系列问题。出现了分页，将内存分割为固定大小的分片来进行管理，在虚拟内存中称为页，相应的在物理内存中称为页帧。**每个页帧中包含一个虚拟内存页**。
页的存在更好增加内存管理分配的灵活性，由于页的大小是固定的，系统很容易计算出程序需要的页数量，并且仍可以将所需要的虚拟页存放在不连续的物理内存页中。
## 页表
上面提到过虚拟页是存在物理内存中的，为了要记录每个虚拟也存在物理内存中的位置就需要**页表(PT)**，它是一种类似数组的数据结构，每个进程都有自己的一张页表，页表中的每一项就叫**页表项(PTE)**，页表记录的是**虚拟内存到物理内存的转换**。
### 转换
虚拟内存如何映射到物理内存并且忤逆地址如何通过页表得到正确的物理地址，这就要冲虚拟地址开始说起。
一个虚拟地址我们分成两个部分看，**虚拟页号(VPN)** 和**虚拟页面偏移量(VPO)**，其中虚拟页号就用来定位页表中的位置。
再说到页表，页表是由多个页表项组成的，每个页表项也是由两部分组成，一个是虚拟页号用来被定位的。还有一部分存的是物理地址的起始位置，也就是**物理页号(PPN)**.
虚拟地址定位到具体的页表项后就可以得到物理页号了，再拼接上虚拟页面偏移量就是一个完整的物理内存地址了。
![[vm4.png|left|500x280]]


>**VPN和VPO的长度计算**    
>假设虚拟地址空间大小是32位，一个页有4KB，则计算虚拟页号和页内偏移量的方法为：
>**虚拟页号VPN：** 32- $log_2({4KB})$ = 32 - 12 =10 
>**页内偏移量Offset：**$log_2({4KB})$ = 12

???+ note
    **VPN和VPO的长度计算**    
    假设虚拟地址空间大小是32位，一个页有4KB，则计算虚拟页号和页内偏移量的方法为：
    **虚拟页号VPN：** 32- $log_2({4KB})$ = 32 - 12 =10 
    **页内偏移量Offset：**$log_2({4KB})$ = 12

### 页表存储
页表通常是存储在内存中的。但也是可以存储在磁盘中，例如 64 位系统，其中页表可能非常庞大。在这种情况下，操作系统可能会使用**多级页表**结构，并将这些页分配到物理内存中。当 CPU 需要进行地址转换时，如果页表中的某一部分未加载到内存中，操作系统会通过**页面交换**或**页面失效**等机制来将所需的页从磁盘加载到内存中，然后进行地址转换。
### 页表项中的信息
页表项中的除了上面的虚拟页号和物理页号，还有一些控制位和元数据。控制位包括有效位、脏位、访问位、保护位、参考位、全局位等。这些位主要用来进行访问控制和页面访问。
保护位：比段能更加细化访问控制，控制读，写，执行等权限。
有效位：标识页表项是否有效，1.表示该页表项对应虚拟页面已经分配完毕物理内存，0                  则表示虚拟页面未分配物理内存。
脏位：    表明页面被带入内存后是否被修改过。
## TLB
假设在32位系统里，一条页表项有4B大小，一个虚拟地址分20位VPN和12位VPO，也就是说操作系统中每个进程都必须为$2^{20}$个地址进行转换，所以每个线程都拥有$2^{20}* 4 / 1024 =4M$大小的页表在内存中。这个占用空间其实不小了，如果多进程下呢？在64位操作系统下呢？**页表容量的增大会带来第一个问题**就是：作为会被频繁访问的页表，每次指令获取，加载或者保存都要额外读一次内存中的页表，如果表数据量大还没优化的情况下一定会带来较高的性能开销。
提高访问速度的一种方式就是加缓存，是的页表的访问也是用了这种方式，只不过它是依靠硬件来支持的。这个硬件叫**地址转换旁路缓冲器(TLB)**，每次内存访问，硬件都会检查啊TLB，如果有期望的转换映射就直接返回 。 
如果不存在，则需要以VPN作为索引从页表中寻找对应的PPN。成功获取后存入TLB，**并会重试该指令**，这次TLB能命中了，直接返回。
## 多级页表
**页表容量的增大会带来第二个问题**就是页表大，内存消耗太多。对于一个32位操作系统来说一张4M的页表可以覆盖整个虚拟空间，但是进程不会只有一个，所以为了性能之类考虑，系统采用**多级页表**。将线性页表变成了类似树的结构。
### 多级页表的结构
多级页表下一个顶级页覆盖整个系统的虚拟空间。因此可以映射到所有线程中的页表。顶级的页表相当于全局结构。

>[!quote] 以下例子来自《深入理解计算机系统》P571页，个人觉得那个例子更清楚点

假设，32位系统中是4G内存，一页有4KB，每个页表条目是4B，所以计算公式是：
$页表大小 =  页表条目大小 * 虚拟地址空间的大小 / 页面的大小= 4B * 4GB/ 4KB = 4M$
![[Pasted image 20240320111357.png]]
这种树形结构很好的节约了空间，1.如果一级表中的一PTE是空的对应的二级页表就不会存在。2.只需要把一级页表存入内存中，至**于后面的子页表可以放入磁盘存储，在有需要的时候从磁盘中换入换出**。
有一点需要注意，上面只展示了两级页表不代表只有两级，对于64位操作系统页表树的级数更多。
###  多级页表下寻址
在线性页表下，虚拟地址分成两部分就可以从页表中找到对应地址，现在换出多级页表虚拟地址也不能简单的划分成两部分了。将虚拟页号VPN划分多个段，用来作为顶级，中间级和页表的索引。每一级页表保存着下一级页表的起始地址。
>[!quote]  如何划分虚拟页号里的页表项索引略去

## 交换空间
上面提到的虚拟内存空间都是与物理空间一般大小，其实系统是可以支持更大的地址空间，计算机中比内存更大的存储就是硬盘了。也就是系统把部分地址空间存储在硬盘上。那么系统是如何利用磁盘提供更大虚拟地址空间的假象？
在硬盘上开辟一部分空间用于物理页的移入移出。这样的空间就是**交换空间**。

>[!info] 未引入交换空间，虚拟地址转换的流程
>1. 程序准备访问数据产生虚拟地址，首先从虚拟地址中获取VPN，硬件TLB检查这个VPN是否命中，如果命中直接获得最终的物理地址并从内存中取数据。 
>2. 如果不存在，则需要以VPN作为索引从页表中寻找对应的PPN。成功获取后存入TLB，**并会重试该指令**，这次TLB能命中了，直接返回。

现在增加了交换空间，而且这部分还存在于磁盘中。所以在访问的机制上有变化。
硬件通过**存在位**进行判断虚拟内存页是否存在物理内存页中。如果存在操作流程如上，如果不存在，就说明在硬盘上。对于访问不在物理内存中的页会触发**缺页异常**
#### 缺页
对于缺页这种异常，由操作系统来处理。通过中断向量表找到处理程序，由软件处理页错误。
一个页如果存在于磁盘中，在处理页错误的时候，操作系统需要将该页交换到内存中。这个页在磁盘上的位置也是存储在PTE上的，通过读取对应的位置去磁盘中找到该页并读入到内存中。
随着磁盘的I/O完成，系统会跟新页表，页表项中的PPN段，存在位。之后重新再次访问，但是依旧未命中，因为目前还在内存中。这次访问会将地址跟新到TLB中。最后再次重新访问就可以命中了。

所以一个典型的缺页处理流程应该是：
1. CPU 生成一个虚拟地址，传入MMU。
2. MMU里面有个TLB硬件，TLB根据虚拟内存中的虚拟页号找对应的物理页号。
3. 如果命中了，则直接从TLB中返回对应的物理地址。
4. 如果未命中，则通过虚拟页号去内存中的页表中寻找。
5. 如果在页表中某一项命中，会去检查对应页表项的存在位，如果是1，则获取到完整物理地址后存入TLB，并且会重新发起指令从TLB中获取结果。
6. 如果存在位是0，说明该虚拟内存页地址在磁盘中，触发缺页异常，控制器由CPU转移到操作系统，通过中断向量表调转到缺页异常处理的程序。
7. 操作系统利用PTE上存储的硬盘地址知道需要从硬盘的何处读取对应的虚拟页。将该虚拟页读入到内存中。
8. 缺页程序的结束后，操作系统会跟新页表，页表项中的PPN段，存在位。CPU再次访问相同的虚拟地址，但此时TLB中找到对应物依旧未命中。导致CPU需要再次访问页表以获取新页面的物理地址。在此之后，TLB跟新。最终，CPU再次发起地址转换时，可以直接从TLB中获取到对应的物理地址。这意味着在缺页处理结束后，CPU通常会执行至少三次访问才能获取到所需的物理地址。
上面的步骤是完整的缺页流程，也是CPU去读取一个虚拟地址的完整方法。
#### 牺牲页
在上面步骤6，7中触发缺页异常，就会去磁盘中找到对应的虚拟页然后读入物理内存中，但是如果此时物理内存页已经满了，那又该如何处理？
操作系统会选择先换出一部分页，以便为即将换入的页留下足够空间。换出就需要选择牺牲页，系统根据算法[^1]并且结合**脏位**来进行选择。
>[!info]
> **脏位**\
>是物理内存页中的虚拟页面，这些页已经被修改过了，内容与它们在磁盘上的原始版本不同。通常来说，页面中被写入数据就将该页面标记为脏位，在进行页面替换时候优先选择脏页作为牺牲页。因为脏页需要写回磁盘保证数据一致性。\
>**为什么选择脏页**\
>之所以选择脏页作为牺牲页的一个主要优点是减少了写回磁盘的次数。一般情况下，操作系统会有一定的策略来定期将内存中的脏页写回到磁盘，以确保数据的持久性和一致性。这些写回操作可能会消耗大量的系统资源和时间。\
>然而，当发生缺页时，需要选择一个页面来作为牺牲页，以便为新页面腾出空间。如果选择的是一个脏页作为牺牲页，那么在选择这个脏页之后，操作系统就可以立即将其写回磁盘，而不必等到定期的写回操作。这样就可以尽快释放物理内存，并且减少了写回磁盘的等待时间，从而提高了系统的响应速度和性能。

牺牲页被选定后，操作系统将写回磁盘上的交换空间，新的页面加载到内存中，并且在页表中跟新对应的页表项。

